{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4156699,"sourceType":"datasetVersion","datasetId":2454054},{"sourceId":5771012,"sourceType":"datasetVersion","datasetId":3316555},{"sourceId":7175818,"sourceType":"datasetVersion","datasetId":4146683},{"sourceId":7175978,"sourceType":"datasetVersion","datasetId":4146803},{"sourceId":7238086,"sourceType":"datasetVersion","datasetId":4191833},{"sourceId":7238621,"sourceType":"datasetVersion","datasetId":4192254}],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Импорт зависимостей**","metadata":{}},{"cell_type":"code","source":"!pip install -U sentence-transformers\n!pip install mlflow\n!pip install optuna\n!pip install ipywidgets\n!jupyter nbextension enable --py widgetsnbextension","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport math\nimport warnings\nimport logging\nimport torch\nimport mlflow\nimport optuna\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\nfrom torch.utils.data import DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom optuna.visualization import plot_optimization_history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\ntorch.manual_seed(RANDOM_STATE)\nwarnings.simplefilter(\"ignore\", UserWarning)\nwarnings.simplefilter(\"ignore\", RuntimeWarning)\npd.set_option('max_colwidth', 400)\nmlflow.set_experiment(\"logging_sbert\")\nlogging.basicConfig(format='%(asctime)s - %(message)s',\n                    datefmt='%Y-%m-%d %H:%M:%S',\n                    level=logging.INFO,\n                    handlers=[logging.StreamHandler()])\nlog_dir = './logs'\nos.makedirs(log_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Набор данных**","metadata":{}},{"cell_type":"code","source":"# !rm -r /kaggle/working/ && !ls /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:23:19.197706Z","iopub.execute_input":"2023-12-20T16:23:19.199319Z","iopub.status.idle":"2023-12-20T16:23:19.206828Z","shell.execute_reply.started":"2023-12-20T16:23:19.199293Z","shell.execute_reply":"2023-12-20T16:23:19.206089Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df = pd.read_excel('/kaggle/input/input-dataset/resume_job_cities_fixed.xlsx')\ndf.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = train_test_split(df, test_size=0.1, random_state=RANDOM_STATE)\ntrain_data = [\n    InputExample(texts=[job_desc, resume_desc], label=float(match))\n    for job_desc, resume_desc, match in zip(train_df['Job Description'], train_df['Resume Description'], train_df['Match'])\n]\ntrain_dataloader = DataLoader(train_data, shuffle=True, batch_size=2, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:23:20.978113Z","iopub.execute_input":"2023-12-20T16:23:20.979126Z","iopub.status.idle":"2023-12-20T16:23:20.995768Z","shell.execute_reply.started":"2023-12-20T16:23:20.979089Z","shell.execute_reply":"2023-12-20T16:23:20.994800Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**Тренировка**","metadata":{}},{"cell_type":"code","source":"def create_evaluator(val_df, evaluator_class, name, batch_size):\n    return evaluator_class(\n        sentences1=val_df['Job Description'].tolist(),\n        sentences2=val_df['Resume Description'].tolist(),\n        labels=val_df['Match'].tolist(),\n        name=name,\n        batch_size=batch_size,\n        show_progress_bar=True,\n        write_csv=True\n    )\n\ndef train_and_evaluate(model, train_dataloader, evaluator, trial, loss_name):\n    model = model.to(device)\n    loss_class = getattr(losses, loss_name)\n    train_loss = loss_class(model=model) \n    mlflow.end_run()\n\n    with mlflow.start_run(run_name=\"ml_sbert\"):\n        lr = trial.suggest_float('lr', 1e-6, 1e-2, log=True)\n        weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-1, log=True)\n        batch_size = trial.suggest_int('batch_size', 2, 32, log=True)\n        epochs = 3\n        warmup_steps = math.ceil(len(train_df) * 0.1)\n        checkpoint_path = './checkpoints'\n        mlflow.log_params({'lr': lr, 'weight_decay': weight_decay, 'batch_size': batch_size, 'loss_name': loss_name})\n\n        for epoch in range(epochs):\n            model.fit(\n                train_objectives=[(train_dataloader, train_loss)],\n                evaluator=evaluator,\n                optimizer_class=torch.optim.AdamW,\n                epochs=epochs,\n                warmup_steps=warmup_steps,\n                optimizer_params={'lr': lr},\n                weight_decay=weight_decay,\n                show_progress_bar=True,\n                save_best_model=True,\n                use_amp=True,\n                checkpoint_path=checkpoint_path,\n                checkpoint_save_steps=1000,\n            )\n            metrics = evaluator(model)\n            print(metrics)\n                    \n            \n            torch.cuda.empty_cache()\n\n    return metrics\n\ndef objective(trial):\n    model_name = \"sberbank-ai/sbert_large_nlu_ru\"\n    model = SentenceTransformer(model_name)\n    loss_name = trial.suggest_categorical('loss_name', ['CosineSimilarityLoss', 'ContrastiveLoss'])\n    evaluator = create_evaluator(val_df, evaluation.BinaryClassificationEvaluator, \"binary_classification_evaluation\", batch_size=32)\n    metrics = train_and_evaluate(model, train_dataloader, evaluator, trial, loss_name)\n    \n    return metrics\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=2)\nbest_params = study.best_params\nprint(\"Лучшие гиперпараметры:\", best_params)\n\nmlflow.log_params(best_params)\nprint(\"Тренировка завершена!\")\n\nfig = optuna.visualization.matplotlib.plot_optimization_history(study)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TEST**","metadata":{}},{"cell_type":"code","source":"best_model_path = \"./checkpoints/best_model\"\nbest_model = SentenceTransformer(best_model_path)\nmlflow.pytorch.log_model(best_model, \"ml_sbert\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_t = pd.read_csv('/kaggle/input/yandex-jobs/vacancies.csv', sep=',')['Raw text']\ndf_t = df_t.to_frame().rename(columns={'Raw text': 'Job Description'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/working/checkpoints","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Последний лучший чекпоинт","metadata":{}},{"cell_type":"code","source":"latest_checkpoint = max(os.listdir('/kaggle/working/checkpoints'), key=lambda x: int(x))\ncheckpoint_filename = f'/kaggle/working/checkpoints/{latest_checkpoint}'\nprint(checkpoint_filename)\n# model.load_state_dict(torch.load(checkpoint_filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Без резюме айтишников","metadata":{}},{"cell_type":"code","source":"from scipy.spatial.distance import cosine\n\nbest_model_path = \"/kaggle/working/checkpoints/1090\"\nbest_model = SentenceTransformer(best_model_path)\njob_descriptions = df_t['Job Description'].tolist()\n\nuser_resume = input('Введите своё резюме')\n\nuser_resume_embedding = best_model.encode(user_resume)\nsimilarity_scores = [1 - cosine(user_resume_embedding, best_model.encode(job_desc)) for job_desc in job_descriptions]\nresult_df = pd.DataFrame({'Job Description': job_descriptions, 'Similarity': similarity_scores})\ntop_10_vacancies = result_df.nlargest(10, 'Similarity')\nprint(\"Топ-10 вакансий для пользовательского резюме:\")\nprint(top_10_vacancies[['Job Description', 'Similarity']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"С резюме айтишников","metadata":{}},{"cell_type":"code","source":"best_model_path = \"/kaggle/working/checkpoints/1090\"\nbest_model = SentenceTransformer(best_model_path)\n\ntest_data = [\n    InputExample(texts=[job_desc, resume_desc], label=float(match))\n    for job_desc, resume_desc, match in zip(df_t['Job Description'], df_t['Resume Description'], df_t['Match'])\n]\ntest_dataloader = DataLoader(test_data, shuffle=False, batch_size=2, pin_memory=True)\n\ntest_evaluator = create_evaluator(df_t, evaluation.BinaryClassificationEvaluator, \"test_evaluation\", batch_size=32)\ntest_metrics = evaluator(model)\nprint(\"Test Metrics:\", test_metrics)\n\nuser_resume = input('Введите своё резюме')\n\nnew_data_embeddings = model.encode(df_t['Job Description'].tolist(), df_t['Resume Description'].tolist())\nnew_data['Similarity'] = model.encode([user_resume] * len(df_t), df_t['Job Description'])\ntop_10_new_data = new_data.nlargest(10, 'Similarity')\nprint(\"Топ-10 вакансий для пользовательского резюме:\")\nprint(top_10_new_data[['Job Description', 'Similarity']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}